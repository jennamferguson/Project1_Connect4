{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Load the dataset\n",
    "data = np.load('your_dataset.npz')\n",
    "\n",
    "# Inspect the keys (names of stored arrays)\n",
    "print(data.files)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract arrays\n",
    "X_train = data['X_train']\n",
    "Y_train = data['Y_train']\n",
    "X_val = data['X_val']\n",
    "Y_val = data['Y_val']\n",
    "X_test = data['X_test']\n",
    "Y_test = data['Y_test']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train / 1.0  # Scale values if needed (e.g., divide by max value)\n",
    "X_val = X_val / 1.0\n",
    "X_test = X_test / 1.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "Y_train = to_categorical(Y_train, num_classes=7)  # Assuming 7 possible moves\n",
    "Y_val = to_categorical(Y_val, num_classes=7)\n",
    "Y_test = to_categorical(Y_test, num_classes=7)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check Shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape, Y_train.shape)  # E.g., (num_samples, 6, 7, 2) and (num_samples, 7)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "\n",
    "cnn_model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(6, 7, 2)),  # Adjust shape if needed\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(7, activation='softmax')  # Output layer with 7 classes\n",
    "])\n",
    "\n",
    "cnn_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_model.fit(X_train, Y_train, validation_data=(X_val, Y_val), epochs=20, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, Dense, Flatten\n",
    "from tensorflow.keras.models import Model\n",
    "import tensorflow as tf\n",
    "\n",
    "def transformer_block(inputs, num_heads, key_dim, ff_dim):\n",
    "    # Multi-head attention\n",
    "    attn_output = tf.keras.layers.MultiHeadAttention(num_heads=num_heads, key_dim=key_dim)(inputs, inputs)\n",
    "    attn_output = tf.keras.layers.LayerNormalization(epsilon=1e-6)(inputs + attn_output)\n",
    "\n",
    "    # Feedforward network\n",
    "    ffn = tf.keras.Sequential([\n",
    "        Dense(ff_dim, activation='relu'),\n",
    "        Dense(inputs.shape[-1])\n",
    "    ])\n",
    "    ffn_output = ffn(attn_output)\n",
    "    ffn_output = tf.keras.layers.LayerNormalization(epsilon=1e-6)(attn_output + ffn_output)\n",
    "\n",
    "    return ffn_output\n",
    "\n",
    "# Build Transformer Model\n",
    "input_layer = Input(shape=(6, 7, 2))  # Adjust shape as needed\n",
    "flattened = Flatten()(input_layer)  # Flatten 6x7x2 to 84\n",
    "transformer_output = transformer_block(flattened, num_heads=4, key_dim=8, ff_dim=32)\n",
    "output_layer = Dense(7, activation='softmax')(transformer_output)\n",
    "\n",
    "transformer_model = Model(inputs=input_layer, outputs=output_layer)\n",
    "transformer_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer_model.fit(X_train, Y_train, validation_data=(X_val, Y_val), epochs=20, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_accuracy = cnn_model.evaluate(X_test, Y_test)\n",
    "transformer_accuracy = transformer_model.evaluate(X_test, Y_test)\n",
    "print(f\"CNN Accuracy: {cnn_accuracy[1]}\")\n",
    "print(f\"Transformer Accuracy: {transformer_accuracy[1]}\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
