{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load the dataset\n",
    "import pickle\n",
    "\n",
    "# Load the dataset from a .pkl file\n",
    "with open('connect4_data.pkl', 'rb') as f:\n",
    "    data = pickle.load(f)\n",
    "\n",
    "required_keys = ['X_train', 'Y_train', 'X_val', 'Y_val', 'X_test', 'Y_test']\n",
    "for key in required_keys:\n",
    "    if key not in data:\n",
    "        raise KeyError(f\"Missing required key in dataset: {key}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the datasets\n",
    "X_train = data['X_train']\n",
    "Y_train = data['Y_train']\n",
    "X_val = data['X_val']\n",
    "Y_val = data['Y_val']\n",
    "X_test = data['X_test']\n",
    "Y_test = data['Y_test']\n",
    "\n",
    "print(\"Data successfully loaded from connect4_data.pkl.\")\n",
    "print(f\"Training data shape: {X_train.shape}, {Y_train.shape}\")\n",
    "print(f\"Validation data shape: {X_val.shape}, {Y_val.shape}\")\n",
    "print(f\"Test data shape: {X_test.shape}, {Y_test.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize input data if necessary\n",
    "X_train = X_train / 1.0  # Scale values, e.g., divide by max value if needed\n",
    "X_val = X_val / 1.0\n",
    "X_test = X_test / 1.0\n",
    "\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Convert labels to one-hot encoding\n",
    "num_classes = 7  # Assuming 7 possible moves\n",
    "Y_train = to_categorical(Y_train, num_classes=num_classes)\n",
    "Y_val = to_categorical(Y_val, num_classes=num_classes)\n",
    "Y_test = to_categorical(Y_test, num_classes=num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "\n",
    "cnn_model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=X_train.shape[1:]),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(num_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "cnn_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "cnn_model.fit(X_train, Y_train, validation_data=(X_val, Y_val), epochs=20, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, Dense, Flatten\n",
    "from tensorflow.keras.models import Model\n",
    "import tensorflow as tf\n",
    "\n",
    "def transformer_block(inputs, num_heads, key_dim, ff_dim):\n",
    "    attn_output = tf.keras.layers.MultiHeadAttention(num_heads=num_heads, key_dim=key_dim)(inputs, inputs)\n",
    "    attn_output = tf.keras.layers.LayerNormalization(epsilon=1e-6)(inputs + attn_output)\n",
    "\n",
    "    ffn = tf.keras.Sequential([\n",
    "        Dense(ff_dim, activation='relu'),\n",
    "        Dense(inputs.shape[-1])\n",
    "    ])\n",
    "    ffn_output = ffn(attn_output)\n",
    "    ffn_output = tf.keras.layers.LayerNormalization(epsilon=1e-6)(attn_output + ffn_output)\n",
    "\n",
    "    return ffn_output\n",
    "\n",
    "input_layer = Input(shape=X_train.shape[1:])\n",
    "flattened = Flatten()(input_layer)\n",
    "transformer_output = transformer_block(flattened, num_heads=4, key_dim=8, ff_dim=32)\n",
    "output_layer = Dense(num_classes, activation='softmax')(transformer_output)\n",
    "\n",
    "transformer_model = Model(inputs=input_layer, outputs=output_layer)\n",
    "transformer_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer_model.fit(X_train, Y_train, validation_data=(X_val, Y_val), epochs=20, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Test\n",
    "cnn_accuracy = cnn_model.evaluate(X_test, Y_test)\n",
    "transformer_accuracy = transformer_model.evaluate(X_test, Y_test)\n",
    "print(f\"CNN Accuracy: {cnn_accuracy[1]}\")\n",
    "print(f\"Transformer Accuracy: {transformer_accuracy[1]}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
